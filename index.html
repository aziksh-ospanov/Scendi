<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="keywords" content="Feature Embedding Comparison, Interpretable Machine Learning, Spectral Clustering, Kernel Matrix Analysis, Deep Representation Learning, CLIP Embedding, Embedding Evaluation, Spectral Methods, Model Comparison, Diversity Evaluation, Prompt-Aware Diversity">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Scendi Score: Prompt-Aware Diversity Evaluation via Schur Complement of CLIP Embeddings</title>

  <meta name="description" content="Scendi Score is a Schur Complement-based metric for measuring prompt-aware diversity for generative models.">
  <meta name="author" content="Azim Ospanov">
  <meta name="robots" content="index, follow">
  <link rel="canonical" href="https://aziksh-ospanov.github.io/Scendi/">

  <!-- Open Graph -->
  <meta property="og:title" content="Scendi Score: Prompt-Aware Diversity Evaluation via Schur Complement of CLIP Embeddings">
  <meta property="og:description" content="Scendi Score is a Schur Complement-based metric for measuring prompt-aware diversity for generative models.">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://aziksh-ospanov.github.io/Scendi/">
  <meta property="og:image" content="https://aziksh-ospanov.github.io/Scendi/static/images/scendi_overview.png">
  <meta property="og:image:alt" content="Scendi Overview Diagram">
  <meta property="og:site_name" content="Scendi: Prompt-Aware Diversity Metric">

  <!-- Twitter Card -->
  <meta name="twitter:title" content="Scendi Score: Prompt-Aware Diversity Evaluation via Schur Complement of CLIP Embeddings">
  <meta name="twitter:description" content="Scendi Score is a Schur Complement-based metric for measuring prompt-aware diversity for generative models.">
  <meta name="twitter:image" content="https://aziksh-ospanov.github.io/Scendi/static/images/scendi_overview.png">

  <!-- Optional LinkedIn Preview -->
  <meta property="og:image:type" content="image/webp">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">

  <!-- Mobile & Verification [change later]-->
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="google-site-verification" content="ez0KnTiK2YpwWuEIBIzrouoYFvZ1QG6UzDMHAk9tiic" />
<meta property="article:published_time" content="2025-06-26T00:00:00Z" />


  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-XW3EW17BPM"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'G-XW3EW17BPM');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/logo.svg">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/swiper@11/swiper-bundle.min.css"/>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/swiper@11/swiper-bundle.min.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://aziksh-ospanov.github.io">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://neurips.cc/virtual/2024/poster/96008">
            Scalable Diversity Evaluation
          </a>
          <a class="navbar-item" href="https://github.com/mjalali/renyi-kernel-entropy">
            RKE Score
          </a>
          <a class="navbar-item" href="https://openreview.net/forum?id=Vb5sG3ZQjE">
            Statistical Complexity of Vendi and RKE
          </a>
          <a class="navbar-item" href="https://arxiv.org/abs/2411.02817">
            Conditional Vendi Score
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">
            <span class="spec-gradient">Scendi Score</span>: Prompt-Aware Diversity Evaluation via Schur Complement of CLIP Embeddings
          </h1>
          
          <!-- <h1 class="title is-1 publication-title">âœ¨ <span class="sparke-gradient">SPARKE</span> : Scalable Prompt-Aware Diversity Guidance in Diffusion Models via RKE Score</h1> -->
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://aziksh-ospanov.github.io">Azim Ospanov</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=NxaTDyUAAAAJ&hl=en">Mohammad Jalali</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.cse.cuhk.edu.hk/~farnia/">Farzan Farnia</a><sup>1</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>The Chinese University of Hong Kong, Department of Computer Science & Engineering </span>
          </div>

          <div class="is-size-4 is-centered publication-venue">
            <span class="sparke-gradient">Accepted at ICCV 2025 (Highlight) </span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>OpenReview</span>
                </a>
              </span>
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2412.18645v3"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2412.18645v3"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a> -->
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/aziksh-ospanov/scendi-score"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Github Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://colab.research.google.com/drive/1gP4MCmKFXcYzWClTqIbiQ-mlsQI4RuyS?usp=sharing"
                class="external-link button is-normal is-rounded is-dark"
                target="_blank" rel="noopener noreferrer">
               <span class="icon">
                 <img src="https://img.icons8.com/?size=100&id=lOqoeP2Zy02f&format=png&color=000000"
                      alt="Colab" style="height: 1em; width: 1em; vertical-align: middle;">
               </span>
               <span>Quick Start (Colab)</span>
               </a>
              </span> -->
              <span class="link-block">
                <a href="#bibtex"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-obp"></i>
                  </span>
                  <span>BibTex</span>
                </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- <video poster="" id="teaser" autoplay controls muted loop playsinline height="100%">
        <source src="./static/videos/spec_ffhq.mp4"
                type="video/mp4">
      </video> -->
      <img src="./static/images/scendi_overview.png">
      </img>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Scendi</span> captures the diversity stemming from generative model itself (left) or specified prompts (right) 
      </h2>
    </div>
  </div>
</section>
<!-- <section class="hero teaser">
  <div class="container is-max-desktop has-text-centered">
    <div class="section">
      <h2 class="title is-3">Overview of SPEC: Comparison and Alignment of Embeddings</h2>
      <img src="./static/images_spec/figure_1.png">
      </img>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">SPEC</span> performs an eigendecomposition of the difference of kernel matrices following the two compared embeddings on a given
        reference dataset. SPEC-align optimizes the alignment of two embeddings by minimizing the SPEC-diff.
      </h2>
    </div>
  </div>
</section> -->

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The use of CLIP embeddings to assess the fidelity of samples produced by text-to-image generative models has been extensively explored in the literature. While the widely adopted CLIPScore, derived from the cosine similarity of text and image embeddings, effectively measures the alignment of a generated image, it does not quantify the diversity of images generated by a text-to-image model. 
          </p>
          <p>
            <!-- In this work, we propose the <em><u><strong>S</strong></u>pectral <u><strong>P</strong></u>airwise-<u><strong>E</strong></u>mbedding <u><strong>C</strong></u>omparison (<strong>SPEC</strong>)
              framework to compare embeddings and identify their differences in clustering a reference dataset. 
              Our approach examines the kernel matrices derived from two embeddings and leverages the eigendecomposition of the difference kernel matrix to detect sample clusters that are captured differently by the two embeddings. -->
              In this work, we extend the application of CLIP embeddings to quantify and interpret the intrinsic diversity of text-to-image models, which are responsible for generating diverse images from similar text prompts, referred to as prompt-aware diversity.  To achieve this, we propose a decomposition of the CLIP-based kernel covariance matrix of image data into text-based and non-text-based components. Using the Schur complement of the joint image-text kernel covariance matrix, we perform this decomposition and define the matrix-based entropy of the decomposed component as the <em><u><strong>S</u></strong>chur <u><strong>C</u></strong>omplement <u><strong>EN</strong></u>topy <u><strong>DI</strong></u>versity (Scendi)</em> score, as a measure of the prompt-aware diversity for prompt-guided generative models. 
          </p>
          <p>
            Additionally, we discuss the application of the Schur complement-based decomposition to nullify the influence of a given prompt on the CLIP embedding of an image, enabling focus or defocus of the embedded vectors on specific objects. We present several numerical results that apply our proposed Scendi score to evaluate text-to-image and LLM (text-to-text) models. Our numerical results indicate the success of the Scendi score in capturing the intrinsic diversity of prompt-guided generative models.
          </p>
        </div>
      </div>
    </div>
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop has-text-centered">
    <div class="section">
      <h2 class="title is-3">Overview of Scendi: Decomposing CLIP Embeddings</h2>
      <img src="./static/images/clip_decomposition.png">
      </img>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Scendi</span> uses Schur Complement-based decomposition on kernel covariance matrices to remove directions specified in prompts. The example shows correlation of the input image with samples from ImageNet after removing
        a certain concept, i.e. <em>"a guitar with cabbage" - "guitar"</em> correlates the most with <em>"cabbage"</em> images.
      </h2>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop has-text-centered">
      <h2 class="title is-3">Scendi Score with Fixed Prompts or Generated Image  Distributions</h2>

      <div class="swiper">
        <div class="swiper-wrapper">
          <div class="swiper-slide">
            <img src="./static/images/doctors_fix_prompts.png" class="carousel-image" />
          </div>
          <div class="swiper-slide">
            <img src="./static/images/doctors_fix_images.png" class="carousel-image" />
          </div>
          <!-- <div class="swiper-slide">
            <img src="./static/images_spec/roberta_e5_mscoco_captions.png" class="carousel-image" />
          </div>
          <div class="swiper-slide">
            <img src="./static/images_spec/wikitext2_roberta_clip.png" class="carousel-image" />
          </div> -->
        </div>

        <!-- Navigation buttons -->
        <div class="swiper-button-prev"></div>
        <div class="swiper-button-next"></div>

        <!-- Optional pagination -->
        <div class="swiper-pagination"></div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop has-text-centered">
    <div class="section">
      <h2 class="title is-3">Comparing the Scendi Score with Other Metrics for Prompt-Based Diversity Evaluation</h2>
      <img src="./static/images/scendi_vs_others.png">
      </img>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Scendi</span> distinguishes between two sources of diversity: the underlying prompts and the generative model itself. When a specific breed is mentioned in the prompts, 
        the score attributes variations in cat breeds to the prompts. However, if the prompts only specify 'cats', then increased diversity in breeds is attributed to the generative model.
      </h2>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop has-text-centered">
    <div class="section">
      <h2 class="title is-3">Effect of CLIP Direction Removal on K-PCA Clusters</h2>
      <img src="./static/images/animals_with_fruits_clustering.png">
      </img>
      <h2 class="subtitle has-text-centered">
        Before decomposition, K-PCA clusters exhibit distinct groupings for animals and fruits. After decomposition, the clusters primarily reflect the remaining direction,
        for example, after removing the 'fruit' component, the clusters focus on animal species, and vice versa. 
      </h2>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop has-text-centered">
    <div class="section">
      <h2 class="title is-3">Scendi and Typographic Attacks</h2>
      <img src="./static/images/typographic_attacks.png">
      </img>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Scendi</span>-based CLIP decomposition can reduce susceptibility to typographic attacks. 
      </h2>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title"><a id="bibtex">BibTeX</a></h2>
    <p>To cite this work, please use the following BibTeX entries:</p>
    <!-- <p>Scendi framework for prompt-aware diversity evaluation:</p> -->
    <pre><code>@inproceedings{
      ospanov2025scendi,
      title = {Scendi Score: Prompt-Aware Diversity Evaluation via Schur Complement of CLIP Embeddings},
      author = {Azim Ospanov and Mohammad Jalali and Farzan Farnia},
      booktitle = {International Conference on Computer Vision},
      year = {2025}
      <!-- url = {https://arxiv.org/html/2412.18645v3} -->
}</code></pre>

    <!-- <p>FINC framework for pairwise comparison of generative models:</p>
    <pre><code>@InProceedings{zhang2025finc,
      author = {Zhang, Jingwei and Jalali, Mohammad and Li, Cheuk Ting and Farnia, Farzan},
      title = {Unveiling Differences in Generative Models: A Scalable Differential Clustering Approach},
      booktitle = {Proceedings of the Computer Vision and Pattern Recognition Conference (CVPR)},
      month = {June},
      year = {2025},
      pages = {8269-8278}
}</code></pre>      -->
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website adapted from the following <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
